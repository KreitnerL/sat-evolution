# Improving SAT-Solvers with a Genetic Algorithm and Deep Reinforcement Learning


## Introduction
This project is an attempt to use Deep Reinforcement Learning together with a genetic algorihm to improve state of the art solvers for the boolean satisfiability problem.
The code is mostly based on the source code of "Learning to Evolve, Jan Schuchardt, Vladimir Golkov, Daniel Cremers [2019]" and the previous work from Yoav Schneider.
The project also contains code that was used for a previous approach that differs heavily from the new approach you can see on the latest presentations slides from 2020. 
The old approach focused on using simple Genetic Algorithms to modify the current solution for a problem. One can think of it as WalkSAT approach. This strategy however has major drawbacks as discussed in the presentation slides and is therefore not really relevant anymore.
Nevertheless, the code may still serve as a reference for future development and thus is still included in the code base.

## Folder structure
### Overview

- `DATA/`:
    Folder containing various satisfiable SAT problems encoded in DIMACS cnf format. The existing problems are taken from [here](https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html), but one also easily create new problem instances using `src/utils/SAT_problem_generator.py`. Note that these problem will be randomly generated and thus are not as hard to solve as the already existing ones.
- `DOCS/`:
    Here you can find all sorts of additional information for the project like presentation slides or blueprints  of the NN architecture.
- `solution/`:
    All solutions and byproducts (e.g. weights, stats,...) generated by a solver will be stored here.
- `scr/`:
    Folder containing all the relevant source code.

### Source Code:


- `/neural_networks/`
    Here you can find many network architectures as well as helpful submodules.
    - `encode_process_decode.py`: The combined actor-critic network for the new message passing approach. It is not yet used by any solver. See comments or https://arxiv.org/abs/1806.01261 for more information
    - `feature_collection.py`: A helper class that wrapps together different sized tensors and symplifies the handling.
    - `message_passing_core.py`: A submodule that implements the MP layer, aka message passing on a graph network.
    - `network.py`: the network from the "Learning to Evolve" paper
    - `pool_conv_sum_nonlin_pool.py`: A submodule implementing a memory efficient + permutation equivariant convolution layer
    - `static_dynamic_network.py`: an improved version for the WalkSAT approach that tries to infer deep problem features while also deciding for an action each time step.
    - `utils.py`: Collection of various utility functions

- `/reinforcement.py/`
    Code for reinforcement learning. Taken from Jan Schuchardt's code based and left unchanged, except for allowing irregular sized training data batches and an additional progressbar for the optimization process.
- `/sat/`
    Code for representing and validating SAT problems. Note that it may need future adaption to work with the new solver type.
    - `cnf3.py`: Code for reading CNF3 problems and evaluating them.
    - `population.py`: Code for representing and modifying a population of CNF3 solutions.
    - `problem loader.py`: Loads SAT3 problems from text files.
    - `solution`: Representing a single CNF3 solution.
- `/solvers/`
    Code for encoding populations and problems for neural networks and running the genetic algorithm. Implementation of new classes based on Jan Schuchardt's code base.
    - `encoding.py`: This class encodes the current state and all relevant input features to be then fed to the neural network.
    - `solvers.py`: Test file implementing different WalkSAT solvers that all rely on genetic strategies. Note that for the new approach one has to implement a completly new solver.
- `/strategies/`
    Implementation for different genetic algorithms strategies that are used by WalkSAT solvers.
- `/utils/`
    Folder containing additional utility functions and test implementations for neural networks.
    - `memory.py`: Class comparing different custom RNN implementations. Not relevant for the code base.
    - `NeuroSAT.py`: A simplified version of the NeuroSAT architecture https://arxiv.org/abs/1802.03685. Not relevant for the code base.
    - `plot_fitness_factors.py`, `plot_mutation_rates.py`: Legacy code by Yoav Schneider. Not relevant for the code base.
    - `SAT_problem_generator.py`: Class to create new random SAT problem instances with arbitrary number of variables / clauses
    - `solve.py`: Implementation for the training and validation process
- `train.py`: File to start training
- `validate.py`: File to start validation

## How to Use

As mentioned in the introduction, the new approach presented in the slides is not fully implemented yet. That means, there is no entry file that you can call to solve SAT problems end to end with the new approach. However, you can run the old WalkSAT approach to get an idea what the final outcome should look like. The following paragraphs describe how to train and validate the old WalkSAT approach.

Be sure to install all the necessary requirements!
```sh
pip install -r requirements.txt
```

Five different solvers are available:
* Individual Mutation
* Gene Mutation
* Crossover
* Selection
* Vanilla

They can be trained using `train.py` with the following syntax
```sh
python3 train.py [solver] [output directory] [weights directory]? [start index]? 
```

- `solver`: Use either gene/individual/crossover/selection to call one of the above mentioned solvers
- `output directory`: folder you want store the statistics in. Folder must already exist!
- `weights directory`: (Optional) Path to the baseline file that can be used to initialize the the network with previously trained weights. 
- `start index`: (Optional) Integer that specifies to start at a specific round of training. Default is 0.

They can be validated using `validation.py` with the following syntax (network weights are expected in the output dir as "baseline")

```sh
python3 validate.py [solver] [output directory] [weights directory]? [start index]? 
```
- `solver`: Use either gene/individual/crossover/selection/vanilla to use 
The validation outputs the average maximum fitness at each generation to a text files at the output direction.
- `output directory`: folder you want store the statistics in. Folder must already exist!
- `weights directory`: (Optional) Path to the baseline file that can be used to initialize the the network with previously trained weights. 
- `start index`: (Optional) Integer that specifies to start at a specific round of training. Default is 0.

# Future Work
See _future work_ section of the slides.