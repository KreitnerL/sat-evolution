https://github.com/ElderResearch/gpu_docker/issues/38

Loss?
    Wenn stagniert auf hohem Level auf allen LR, Archtitektur nicht gut!

Hyperparamter wo anfangen?
    Bottom up approach. Auf einfachen Problemen geringer HL anzahl und nicht zu wenig
    Filtern! Learning rate oft genug ändern! Nutze Seed, aber hin und wieder auch ohne Seed
    um nicht zu abhängig zu sein!

Crossover / Selection / ...?
    Konzentriere dich auch die vielversprechenden!

Truncated Backpropagation through time

GxG memory

parallel streams